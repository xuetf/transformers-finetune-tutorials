{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TRANSFORMERS_CACHE'] = 'model_files/'\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download or load model\n",
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-chinese')\n",
    "model = AutoModel.from_pretrained('bert-base-chinese')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<transformers.tokenization_bert.BertTokenizer at 0x1a4b2fbac8>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer # BertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(21128, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model # BertModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tokenizer重要接口\n",
    "- tokenize\n",
    "- encode\n",
    "- convert_ids_to_tokens\n",
    "- convert_tokens_to_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 直接调用(重载了__call__)\n",
    "\n",
    "直接调用\n",
    "Main method to tokenize and prepare for the model one or several sequence(s) or one or several pair(s) of sequences.\n",
    "\n",
    "__call__(text: Union[str, List[str], List[List[str]]], text_pair: Optional[Union[str, List[str], List[List[str]]]] = None, add_special_tokens: bool = True, padding: Union[bool, str, transformers.file_utils.PaddingStrategy] = False, truncation: Union[bool, str, transformers.tokenization_utils_base.TruncationStrategy] = False, max_length: Optional[int] = None, stride: int = 0, is_split_into_words: bool = False, pad_to_multiple_of: Optional[int] = None, return_tensors: Optional[Union[str, transformers.file_utils.TensorType]] = None, return_token_type_ids: Optional[bool] = None, return_attention_mask: Optional[bool] = None, return_overflowing_tokens: bool = False, return_special_tokens_mask: bool = False, return_offsets_mapping: bool = False, return_length: bool = False, verbose: bool = True, **kwargs) → transformers.tokenization_utils_base.BatchEncoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 3217, 4697, 679, 6230, 3236, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer('春眠不觉晓')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [[101, 3217, 4697, 679, 6230, 3236, 102]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1]]}"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(['春眠不觉晓'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tokenize\n",
    "\n",
    "分词接口\n",
    "(text: str, **kwargs) → List[str]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['春', '眠', '不', '觉', '晓']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.tokenize('春眠不觉晓')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## encode\n",
    "\n",
    "输入是单个句子sentence，返回[CLS] [SEP] 修饰好的input_ids\n",
    "\n",
    "encode(text: Union[str, List[str], List[int]], text_pair: Optional[Union[str, List[str], List[int]]] = None, add_special_tokens: bool = True, padding: Union[bool, str, transformers.file_utils.PaddingStrategy] = False, truncation: Union[bool, str, transformers.tokenization_utils_base.TruncationStrategy] = False, max_length: Optional[int] = None, stride: int = 0, return_tensors: Optional[Union[str, transformers.file_utils.TensorType]] = None, **kwargs) → List[int]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 101, 3217, 4697,  679, 6230, 3236,  102]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids = tokenizer.encode('春眠不觉晓', return_tensors='pt')\n",
    "input_ids "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3217, 4697,  679, 6230, 3236]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode('春眠不觉晓', return_tensors='pt', add_special_tokens=False) # 不加特殊符号"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1905, 1905, 7319, 1582, 7881]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode('处处闻啼鸟', add_special_tokens=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3217, 4697, 679, 6230, 3236]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids_1 = tokenizer.encode('春眠不觉晓', add_special_tokens=False) # 默认返回list\n",
    "input_ids_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1905, 1905, 7319, 1582, 7881]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids_2 = tokenizer.encode('处处闻啼鸟', add_special_tokens=False)\n",
    "input_ids_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## convert_ids_to_tokens\n",
    "\n",
    "输入是id list，输出对应的原始tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[UNK]', '[CLS]', '[SEP]']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 101: [CLS],  102: [SEP]\n",
    "tokenizer.convert_ids_to_tokens(['100', '101', '102'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## convert_ids_to_tokens\n",
    "\n",
    "输入是token list，输出是对应的id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3217, 4697, 679, 6230, 3236]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.convert_tokens_to_ids(['春', '眠', '不', '觉', '晓'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## build_inputs_with_special_tokens\n",
    "\n",
    "输入是两个句子的ID，输出是拼接好特殊符号的句子\n",
    "\n",
    "Build model inputs from a sequence or a pair of sequence for sequence classification tasks by concatenating and adding special tokens. A BERT sequence has the following format:\n",
    "\n",
    "single sequence: [CLS] X [SEP]\n",
    "\n",
    "pair of sequences: [CLS] A [SEP] B [SEP]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[101, 3217, 4697, 679, 6230, 3236, 102, 1905, 1905, 7319, 1582, 7881, 102]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.build_inputs_with_special_tokens(\n",
    "    input_ids_1, \n",
    "    input_ids_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create_token_type_ids_from_sequences\n",
    "\n",
    "输出segment id：包括了特殊字符\n",
    "\n",
    "(token_ids_0: List[int], token_ids_1: Optional[List[int]] = None) → List[int]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.create_token_type_ids_from_sequences(\n",
    "    input_ids_1,\n",
    "    input_ids_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get_special_tokens_mask\n",
    "\n",
    "输出特殊字符的mask序列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.get_special_tokens_mask(input_ids_1, input_ids_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## encode_plus\n",
    "输出 input_ids， token_type_ids, attention_mask\n",
    "\n",
    "encode_plus(text: Union[str, List[str], List[int]], text_pair: Optional[Union[str, List[str], List[int]]] = None, add_special_tokens: bool = True, padding: Union[bool, str, transformers.file_utils.PaddingStrategy] = False, truncation: Union[bool, str, transformers.tokenization_utils_base.TruncationStrategy] = False, max_length: Optional[int] = None, stride: int = 0, is_split_into_words: bool = False, pad_to_multiple_of: Optional[int] = None, return_tensors: Optional[Union[str, transformers.file_utils.TensorType]] = None, return_token_type_ids: Optional[bool] = None, return_attention_mask: Optional[bool] = None, return_overflowing_tokens: bool = False, return_special_tokens_mask: bool = False, return_offsets_mapping: bool = False, return_length: bool = False, verbose: bool = True, **kwargs) → transformers.tokenization_utils_base.BatchEncoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 3217, 4697, 679, 6230, 3236, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode_plus('春眠不觉晓',) # 单个句子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 3217, 4697, 679, 6230, 3236, 102, 1905, 1905, 7319, 1582, 7881, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode_plus('春眠不觉晓', '处处闻啼鸟') # 两个句子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 4495, 2496, 868, 782, 3345, 102, 3647, 771, 711, 7787, 7413, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode_plus('生当作人杰', '死亦为鬼雄') # 两个句子"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## batch_encode_plus\n",
    "\n",
    "batch_encode_plus(batch_text_or_text_pairs: Union[List[str], List[Tuple[str, str]], List[List[str]], List[Tuple[List[str], List[str]]], List[List[int]], List[Tuple[List[int], List[int]]]], add_special_tokens: bool = True, padding: Union[bool, str, transformers.file_utils.PaddingStrategy] = False, truncation: Union[bool, str, transformers.tokenization_utils_base.TruncationStrategy] = False, max_length: Optional[int] = None, stride: int = 0, is_split_into_words: bool = False, pad_to_multiple_of: Optional[int] = None, return_tensors: Optional[Union[str, transformers.file_utils.TensorType]] = None, return_token_type_ids: Optional[bool] = None, return_attention_mask: Optional[bool] = None, return_overflowing_tokens: bool = False, return_special_tokens_mask: bool = False, return_offsets_mapping: bool = False, return_length: bool = False, verbose: bool = True, **kwargs) → transformers.tokenization_utils_base.BatchEncoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [[101, 3217, 4697, 679, 6230, 3236, 102]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1]]}"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.batch_encode_plus(['春眠不觉晓'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [[101, 3217, 4697, 679, 6230, 3236, 102, 1905, 1905, 7319, 1582, 7881, 102], [101, 4495, 2496, 868, 782, 3345, 102, 3647, 771, 711, 7787, 7413, 102]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1], [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.batch_encode_plus([['春眠不觉晓','处处闻啼鸟'],  ['生当作人杰', '死亦为鬼雄']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BertModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    res = model(input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 101, 3217, 4697,  679, 6230, 3236,  102]])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 7, 768]), torch.Size([1, 768]))"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sequence_output, pooled_output\n",
    "res[0].shape, res[1].shape # 包括了CLS和SEP的向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setence_embedding(sentences, is_norm=True):\n",
    "    sample_dict = tokenizer(sentences, return_tensors='pt', padding=True)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        sample_output = model(**sample_dict)\n",
    "    \n",
    "    # (B, 7, 768)\n",
    "    token_embeddings = sample_output[0]  # First element of model_output contains all token embeddings\n",
    "    \n",
    "    attention_mask = sample_dict['attention_mask'] # (1, 7)\n",
    "    \n",
    "    # (B, 7, 1)\n",
    "    input_mask_expanded = attention_mask.unsqueeze(-1) # .expand(token_embeddings.size()).float()\n",
    "    \n",
    "    # (B, 7, 768) => (B, 768)\n",
    "    sum_embeddings = torch.sum(token_embeddings * input_mask_expanded, axis=1)\n",
    "    \n",
    "    # (B, 768) /  (B, )\n",
    "    sum_mask = torch.clamp(input_mask_expanded.sum(axis=1), min=1e-9)\n",
    "    \n",
    "    # (B, 768)\n",
    "    mean_embeddings = sum_embeddings / sum_mask\n",
    "    \n",
    "    if is_norm:\n",
    "        mean_embeddings = F.normalize(mean_embeddings, p=2, dim=1)\n",
    "    \n",
    "    return mean_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = ['春眠不觉晓', '处处闻啼鸟', '生当作人杰', '死亦为鬼雄']\n",
    "sentences = ['春眠不觉晓','大梦谁先觉','浓睡不消残酒','东临碣石以观沧海']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_sent_embeds = setence_embedding(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = norm_sent_embeds.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_matrix = np.around(np.dot(m, m.T), decimals=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.   , 0.754, 0.833, 0.57 ],\n",
       "       [0.754, 1.   , 0.723, 0.505],\n",
       "       [0.833, 0.723, 1.   , 0.585],\n",
       "       [0.57 , 0.505, 0.585, 1.   ]], dtype=float32)"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.rcParams['font.sans-serif'] = ['Arial Unicode MS']\n",
    "font_path=\"/System/Library/fonts/PingFang.ttc\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(sim_matrix, cmap=\"hot_r\",\n",
    "                 xticklabels=sentences, yticklabels=sentences)  # 去除纵、横轴 label\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py36",
   "language": "python",
   "name": "py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
